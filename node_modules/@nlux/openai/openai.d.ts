import { DataTransferMode, ChatAdapterBuilder as ChatAdapterBuilder$1, StandardChatAdapter } from '@nlux/core';
export { ChatAdapter, DataTransferMode, StandardChatAdapter, StreamingAdapterObserver, debug } from '@nlux/core';

type OpenAiModel = (string & {}) | 'gpt-4-0125-preview' | 'gpt-4-turbo-preview' | 'gpt-4-1106-preview' | 'gpt-4-vision-preview' | 'gpt-4' | 'gpt-4-0314' | 'gpt-4-0613' | 'gpt-4-32k' | 'gpt-4-32k-0314' | 'gpt-4-32k-0613' | 'gpt-3.5-turbo' | 'gpt-3.5-turbo-16k' | 'gpt-3.5-turbo-0301' | 'gpt-3.5-turbo-0613' | 'gpt-3.5-turbo-1106' | 'gpt-3.5-turbo-0125' | 'gpt-3.5-turbo-16k-0613';

type ChatAdapterOptions = {
    dataTransferMode?: DataTransferMode;
    model?: OpenAiModel;
    apiKey: string;
    systemMessage?: string;
};

interface ChatAdapterBuilder extends ChatAdapterBuilder$1 {
    /**
     * Create a new ChatGPT API adapter.
     * Adapter users don't need to call this method directly. It will be called by nlux when the adapter is expected
     * to be created.
     *
     * @returns {StandardChatAdapter}
     */
    create(): StandardChatAdapter;
    /**
     * The API key to use to connect to ChatGPT API.
     * This is secret and should not be shared publicly or hosted when deploying your application.
     *
     * @optional
     * @param {string} apiKey
     * @returns {ChatAdapterBuilder}
     */
    withApiKey(apiKey: string): ChatAdapterBuilder;
    /**
     * Instruct the adapter to connect to API and load data either in streaming mode or in fetch mode.
     * The `stream` mode would use protocols such as websockets or server-side events, and nlux will display data as
     * it's being generated by the server. The `fetch` mode would use a single request to fetch data, and the response
     * would only be displayed once the entire message is loaded.
     *
     * @optional
     * @default 'stream'
     * @returns {ChatAdapterBuilder}
     */
    withDataTransferMode(mode: DataTransferMode): ChatAdapterBuilder;
    /**
     * The model or the endpoint to use for ChatGPT Inference API.
     * You should provide either a model or an endpoint, but not both.
     * For more information, please refer to the
     * [nlux ChatGPT documentation](https://docs.nlux.ai/category/nlux-with-openai-face).
     *
     * @param {string} model
     * @returns {ChatAdapterBuilder}
     */
    withModel(model: string): ChatAdapterBuilder;
    /**
     * The initial system to send to ChatGPT API.
     *
     * @optional
     * @param {string} message
     * @returns {ChatAdapterBuilder}
     */
    withSystemMessage(message: string): ChatAdapterBuilder;
}

declare const createUnsafeChatAdapter: () => ChatAdapterBuilder;

export { type ChatAdapterBuilder, type ChatAdapterOptions, type OpenAiModel, createUnsafeChatAdapter };
