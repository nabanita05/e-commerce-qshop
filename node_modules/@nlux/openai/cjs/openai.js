"use strict";var e=require("@nlux/core"),t=require("openai");const s="stream",a=e=>{if("object"==typeof e&&null!==e){if("invalid_api_key"===e.code)return"NX-NT-002";if(e.message?.toLowerCase().includes("connection error"))return"NX-NT-001"}return null},r=e=>{switch(e){case"system":return"system";case"user":default:return"user";case"ai":return"assistant"}},o=e=>e.map((e=>({role:r(e.role),content:e.message}))),i=Object.freeze({id:"nlux-openai-adapter",capabilities:{chat:!0,fileUpload:!1,speechToText:!1,textToSpeech:!1}});class n{constructor({systemMessage:a,apiKey:r,dataTransferMode:o,model:i}){this.systemMessage="Act as a helpful assistant to the user",this.__instanceId=`${this.info.id}-${e.uid()}`,this.theDataTransferMode=o??s,this.model=i??"gpt-3.5-turbo",this.openai=new t({apiKey:r,dangerouslyAllowBrowser:!0}),a&&(this.systemMessage=a),e.warn('OpenAI GPT adapter has been initialized in browser mode using option "dangerouslyAllowBrowser". To learn more about OpenAI\' recommendation for handling API keys, please visit:\nhttps://help.openai.com/en/articles/5112595-best-practices-for-api-key-safety\nThe useUnsafeChatAdapter/createUnsafeChatAdapter are only intended for development and testing purposes.\n\nFor production use, we recommend that you implement a server-side proxy and configure a customized adapter for it. To learn more about how to create custom adapters for nlux, visit:\nhttps://nlux.dev/learn/adapters/custom-adapters')}get dataTransferMode(){return this.theDataTransferMode}get id(){return this.__instanceId}get info(){return i}}class l extends n{constructor({apiKey:e,model:t,systemMessage:s}){super({apiKey:e,model:t,systemMessage:s,dataTransferMode:"fetch"}),void 0!==s&&s.length>0&&(this.systemMessage=s)}async fetchText(t,s){const r=this.systemMessage?[{role:"system",content:this.systemMessage}]:[];s.conversationHistory&&r.push(...o(s.conversationHistory)),r.push({role:"user",content:t});try{const t=await this.openai.chat.completions.create({stream:!1,model:this.model,messages:r}),s=await(async e=>{if(!e.choices||!e.choices[0])throw Error("Invalid payload");const t=e.choices[0].message?.content;if(null!==t)return t})(t);return void 0===s?(e.warn("Undecodable message received from OpenAI"),""):s}catch(t){throw e.warn("Error while making API call to OpenAI"),e.warn(t),new e.NluxUsageError({source:this.constructor.name,message:t?.message||"Error while making API call to OpenAI",exceptionId:a(t)??void 0})}}streamText(t,s,a){throw new e.NluxUsageError({source:this.constructor.name,message:"Cannot stream text from the fetch adapter!"})}}const c=async e=>{if(!e.choices||!e.choices[0])throw Error("Invalid payload");const t=e.choices[0].delta.content;if("string"==typeof t)return t};class d extends n{constructor({apiKey:e,model:t,systemMessage:s}){super({apiKey:e,model:t,systemMessage:s,dataTransferMode:"stream"}),void 0!==s&&s.length>0&&(this.systemMessage=s)}fetchText(t){throw new e.NluxUsageError({source:this.constructor.name,message:"Cannot fetch text from the streaming adapter!"})}streamText(t,s,r){const i=this.systemMessage?[{role:"system",content:this.systemMessage}]:[];r.conversationHistory&&i.push(...o(r.conversationHistory)),i.push({role:"user",content:t}),this.openai.chat.completions.create({stream:!0,model:this.model,messages:i}).then((async t=>{let a=t[Symbol.asyncIterator](),r=await a.next();for(;!r.done;){const t=r.value;if("stop"===(t.choices?.length>0?t.choices[0].finish_reason:void 0))break;const o=await c(t);void 0!==o?s.next(o):(e.warn("Undecodable message"),e.warn(t)),r=await a.next()}s.complete()})).catch((t=>{e.warn(t),s.error(new e.NluxUsageError({source:this.constructor.name,message:t.message,exceptionId:a(t)??void 0}))}))}}class h{constructor(e){this.apiKey=null,this.dataTransferMode=s,this.model=null,this.systemMessage=null,this.withApiKeyCalled=!1,this.withDataTransferModeCalled=!1,this.withModelCalled=!1,this.withSystemMessageCalled=!1,e&&(this.apiKey=e.apiKey,this.dataTransferMode=e.dataTransferMode,this.model=e.model,this.systemMessage=e.systemMessage,this.withApiKeyCalled=e.withApiKeyCalled,this.withSystemMessageCalled=e.withSystemMessageCalled,this.withModelCalled=e.withModelCalled,this.withDataTransferModeCalled=e.withDataTransferModeCalled)}create(){if(!this.apiKey)throw new e.NluxUsageError({source:this.constructor.name,message:"Unable to create OpenAI adapter. API key is missing. Make sure you are calling withApiKey() before calling create()."});const t={apiKey:this.apiKey,dataTransferMode:this.dataTransferMode,model:this.model??void 0,systemMessage:this.systemMessage??void 0};return"stream"===this.dataTransferMode?new d(t):new l(t)}withApiKey(t){if(this.withApiKeyCalled)throw new e.NluxUsageError({source:this.constructor.name,message:"Unable to set API key. API key setter has already been called by this builder. Make sure you are not calling withApiKey() twice."});return this.apiKey=t,this.withApiKeyCalled=!0,this}withDataTransferMode(t){if(this.withDataTransferModeCalled)throw new e.NluxUsageError({source:this.constructor.name,message:"Unable to set data loading mode. Stream or fetch setter has already been called by this builder. Make sure you are not calling stream() or fetch() twice."});return this.dataTransferMode=t,this.withDataTransferModeCalled=!0,this}withModel(t){if(this.withModelCalled)throw new e.NluxUsageError({source:this.constructor.name,message:"Unable to set model. Model setter has already been called by this builder. Make sure you are not calling withModel() twice."});return this.model=t,this.withModelCalled=!0,this}withSystemMessage(t){if(this.withSystemMessageCalled)throw new e.NluxUsageError({source:this.constructor.name,message:"Unable to set initial system message. Initial system message setter has already been called by this builder. Make sure you are not calling withSystemMessage() twice."});return this.systemMessage=t??null,this.withSystemMessageCalled=!0,this}}Object.defineProperty(exports,"debug",{enumerable:!0,get:function(){return e.debug}}),exports.createUnsafeChatAdapter=()=>(e.warnOnce("You just have created an OpenAI adapter that connects to the API directly from the browser. This is not recommended for production use. We recommend that you implement a server-side proxy and configure a customized adapter for it. To learn more about how to create custom adapters for nlux, visit:\nhttps://nlux.dev/learn/adapters/custom-adapters"),new h);
